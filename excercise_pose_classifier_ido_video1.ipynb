{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cptgingerbeard/good-fall/blob/main/excercise_pose_classifier_ido_video1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t60tyNn_sW_"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahWmmo3Mjfbr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "print(\"MediaPipe imported successfully!\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "!pip install --upgrade numpy pandas tensorflow keras opencv-python mediapipe"
      ],
      "metadata": {
        "id": "VUOVQ3Wz635k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwA9PPv4_sXE"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import plotly.graph_objects as go\n",
        "import imageio\n",
        "import pickle\n",
        "#import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBe9EDGu_sXG"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYywg98c_sXH"
      },
      "outputs": [],
      "source": [
        "# Define all landmarks in uppercase\n",
        "LANDMARKS = [\n",
        "    \"NOSE\",\n",
        "    \"LEFT_EYE_INNER\",\n",
        "    \"LEFT_EYE\",\n",
        "    \"LEFT_EYE_OUTER\",\n",
        "    \"RIGHT_EYE_INNER\",\n",
        "    \"RIGHT_EYE\",\n",
        "    \"RIGHT_EYE_OUTER\",\n",
        "    \"LEFT_EAR\",\n",
        "    \"RIGHT_EAR\",\n",
        "    \"MOUTH_LEFT\",\n",
        "    \"MOUTH_RIGHT\",\n",
        "    \"LEFT_SHOULDER\",\n",
        "    \"RIGHT_SHOULDER\",\n",
        "    \"LEFT_ELBOW\",\n",
        "    \"RIGHT_ELBOW\",\n",
        "    \"LEFT_WRIST\",\n",
        "    \"RIGHT_WRIST\",\n",
        "    \"LEFT_PINKY\",\n",
        "    \"RIGHT_PINKY\",\n",
        "    \"LEFT_INDEX\",\n",
        "    \"RIGHT_INDEX\",\n",
        "    \"LEFT_THUMB\",\n",
        "    \"RIGHT_THUMB\",\n",
        "    \"LEFT_HIP\",\n",
        "    \"RIGHT_HIP\",\n",
        "    \"LEFT_KNEE\",\n",
        "    \"RIGHT_KNEE\",\n",
        "    \"LEFT_ANKLE\",\n",
        "    \"RIGHT_ANKLE\",\n",
        "    \"LEFT_HEEL\",\n",
        "    \"RIGHT_HEEL\",\n",
        "    \"LEFT_FOOT_INDEX\",\n",
        "    \"RIGHT_FOOT_INDEX\"\n",
        "]\n",
        "\n",
        "BODY_ANGLES = ['left_elbow_angle',\n",
        " 'right_elbow_angle',\n",
        " 'left_armpit_angle',\n",
        " 'right_armpit_angle',\n",
        " 'left_hip_angle',\n",
        " 'right_hip_angle',\n",
        " 'left_knee_angle',\n",
        " 'right_knee_angle',\n",
        " 'left_side_collarbone_angle',\n",
        " 'right_side_collarbone_angle']\n",
        "\n",
        "BODY_HEIGHTS = [\n",
        "    'shoulder_width_x', 'shoulder_width_y',\n",
        "    'hip_width_x', 'hip_width_y',\n",
        "    'left_elbow_wrist_distance_x', 'left_elbow_wrist_distance_y',\n",
        "    'right_elbow_wrist_distance_x', 'right_elbow_wrist_distance_y',\n",
        "    'left_elbow_shoulder_distance_x', 'left_elbow_shoulder_distance_y',\n",
        "    'right_elbow_shoulder_distance_x', 'right_elbow_shoulder_distance_y',\n",
        "    'left_shoulder_hip_alignment_x', 'left_shoulder_hip_alignment_y',\n",
        "    'right_shoulder_hip_alignment_x', 'right_shoulder_hip_alignment_y',\n",
        "    'left_knee_ankle_distance_x', 'left_knee_ankle_distance_y',\n",
        "    'right_knee_ankle_distance_x', 'right_knee_ankle_distance_y',\n",
        "    'left_knee_hip_distance_x', 'left_knee_hip_distance_y',\n",
        "    'right_knee_hip_distance_x', 'right_knee_hip_distance_y',\n",
        "    'left_hand_shoulder_distance_x', 'left_hand_shoulder_distance_y',\n",
        "    'right_hand_shoulder_distance_x', 'right_hand_shoulder_distance_y',\n",
        "    'left_hand_nose_distance_x', 'left_hand_nose_distance_y',\n",
        "    'right_hand_nose_distance_x', 'right_hand_nose_distance_y',\n",
        "    'left_hand_hip_distance_x', 'left_hand_hip_distance_y',\n",
        "    'right_hand_hip_distance_x', 'right_hand_hip_distance_y',\n",
        "    'foot_spread_x', 'foot_spread_y'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPNVvne7_sXI"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNPJLyg2_sXI"
      },
      "outputs": [],
      "source": [
        "# Helper function to get coordinates of a landmark\n",
        "def get_coords(landmark, df_frame):\n",
        "    coords = df_frame[df_frame['landmark'] == landmark][['x', 'y', 'z']].values\n",
        "    return coords[0] if len(coords) > 0 else None\n",
        "\n",
        "# Calculate vector between two points\n",
        "def calc_vector(p1, p2):\n",
        "    return np.array(p2) - np.array(p1)\n",
        "\n",
        "# Calculate angle between two vectors using the dot product\n",
        "def angle_between(v1, v2):\n",
        "    dot_product = np.dot(v1, v2)\n",
        "    norm_v1 = np.linalg.norm(v1)\n",
        "    norm_v2 = np.linalg.norm(v2)\n",
        "    cos_theta = dot_product / (norm_v1 * norm_v2)\n",
        "    angle = np.arccos(np.clip(cos_theta, -1.0, 1.0))  # Clip to avoid numerical errors\n",
        "    return np.degrees(angle)\n",
        "\n",
        "def get_body_vecs(coordinates):\n",
        "    # Upper arms\n",
        "    left_upper_arm = calc_vector(coordinates['LEFT_SHOULDER'], coordinates['LEFT_ELBOW'])\n",
        "    right_upper_arm = calc_vector(coordinates['RIGHT_SHOULDER'], coordinates['RIGHT_ELBOW'])\n",
        "\n",
        "    # Forearms\n",
        "    left_forearm = calc_vector(coordinates['LEFT_ELBOW'], coordinates['LEFT_WRIST'])\n",
        "    right_forearm = calc_vector(coordinates['RIGHT_ELBOW'], coordinates['RIGHT_WRIST'])\n",
        "\n",
        "    # Upper legs\n",
        "    left_upper_leg = calc_vector(coordinates['LEFT_HIP'], coordinates['LEFT_KNEE'])\n",
        "    right_upper_leg = calc_vector(coordinates['RIGHT_HIP'], coordinates['RIGHT_KNEE'])\n",
        "\n",
        "    # Lower legs\n",
        "    left_lower_leg = calc_vector(coordinates['LEFT_KNEE'], coordinates['LEFT_ANKLE'])\n",
        "    right_lower_leg = calc_vector(coordinates['RIGHT_KNEE'], coordinates['RIGHT_ANKLE'])\n",
        "\n",
        "    # Groin (hip-to-hip vector)\n",
        "    groin = calc_vector(coordinates['LEFT_HIP'], coordinates['RIGHT_HIP'])\n",
        "\n",
        "    # Collarbones (shoulder-to-shoulder vector)\n",
        "    collarbones = calc_vector(coordinates['LEFT_SHOULDER'], coordinates['RIGHT_SHOULDER'])\n",
        "\n",
        "    # Sides\n",
        "    right_side = calc_vector(coordinates['RIGHT_SHOULDER'], coordinates['RIGHT_HIP'])\n",
        "    left_side = calc_vector(coordinates['LEFT_SHOULDER'], coordinates['LEFT_HIP'])\n",
        "\n",
        "    # Return all vectors in a dictionary\n",
        "    return {\n",
        "        \"left_upper_arm\": left_upper_arm,\n",
        "        \"right_upper_arm\": right_upper_arm,\n",
        "        \"left_forearm\": left_forearm,\n",
        "        \"right_forearm\": right_forearm,\n",
        "        \"left_upper_leg\": left_upper_leg,\n",
        "        \"right_upper_leg\": right_upper_leg,\n",
        "        \"left_lower_leg\": left_lower_leg,\n",
        "        \"right_lower_leg\": right_lower_leg,\n",
        "        \"groin\": groin,\n",
        "        \"collarbones\": collarbones,\n",
        "        \"right_side\": right_side,\n",
        "        \"left_side\": left_side\n",
        "    }\n",
        "\n",
        "# Calculate Angles\n",
        "def calculate_body_angles(vectors):\n",
        "    # Elbow angles (between upper arm and forearm)\n",
        "    left_elbow_angle = angle_between(vectors['left_upper_arm'], vectors['left_forearm'])\n",
        "    right_elbow_angle = angle_between(vectors['right_upper_arm'], vectors['right_forearm'])\n",
        "\n",
        "    # Armpit angles (between upper arm and collarbones)\n",
        "    left_armpit_angle = angle_between(vectors['left_upper_arm'], vectors['collarbones'])\n",
        "    right_armpit_angle = angle_between(vectors['right_upper_arm'], vectors['collarbones'])\n",
        "\n",
        "    # Hip angles (between upper leg and side vectors, representing torso alignment)\n",
        "    left_hip_angle = angle_between(vectors['left_upper_leg'], vectors['left_side'])\n",
        "    right_hip_angle = angle_between(vectors['right_upper_leg'], vectors['right_side'])\n",
        "\n",
        "    # Knee angles (between upper leg and lower leg)\n",
        "    left_knee_angle = angle_between(vectors['left_upper_leg'], vectors['left_lower_leg'])\n",
        "    right_knee_angle = angle_between(vectors['right_upper_leg'], vectors['right_lower_leg'])\n",
        "\n",
        "    # Side to collarbone angles (lateral torso tilt)\n",
        "    left_side_collarbone_angle = angle_between(vectors['left_side'], vectors['collarbones'])\n",
        "    right_side_collarbone_angle = angle_between(vectors['right_side'], vectors['collarbones'])\n",
        "\n",
        "    # Return all angles in a dictionary\n",
        "    return {\n",
        "        \"left_elbow_angle\": left_elbow_angle,\n",
        "        \"right_elbow_angle\": right_elbow_angle,\n",
        "        \"left_armpit_angle\": left_armpit_angle,\n",
        "        \"right_armpit_angle\": right_armpit_angle,\n",
        "        \"left_hip_angle\": left_hip_angle,\n",
        "        \"right_hip_angle\": right_hip_angle,\n",
        "        \"left_knee_angle\": left_knee_angle,\n",
        "        \"right_knee_angle\": right_knee_angle,\n",
        "        \"left_side_collarbone_angle\": left_side_collarbone_angle,\n",
        "        \"right_side_collarbone_angle\": right_side_collarbone_angle\n",
        "    }\n",
        "\n",
        "# Helper function to calculate differences in x and y directions between two points\n",
        "def calc_xy_difference(p1, p2):\n",
        "    return p2[0] - p1[0], p2[1] - p1[1]\n",
        "\n",
        "# Calculate Heights\n",
        "def calculate_body_heights(coordinates):\n",
        "    # Calculate relevant x and y differences\n",
        "    heights = {\n",
        "        # Shoulder width (left shoulder to right shoulder)\n",
        "        \"shoulder_width_x\": calc_xy_difference(coordinates['LEFT_SHOULDER'], coordinates['RIGHT_SHOULDER'])[0],\n",
        "        \"shoulder_width_y\": calc_xy_difference(coordinates['LEFT_SHOULDER'], coordinates['RIGHT_SHOULDER'])[1],\n",
        "\n",
        "        # Hip width (left hip to right hip)\n",
        "        \"hip_width_x\": calc_xy_difference(coordinates['LEFT_HIP'], coordinates['RIGHT_HIP'])[0],\n",
        "        \"hip_width_y\": calc_xy_difference(coordinates['LEFT_HIP'], coordinates['RIGHT_HIP'])[1],\n",
        "\n",
        "        # Elbow-Wrist distance for arms\n",
        "        \"left_elbow_wrist_distance_x\": calc_xy_difference(coordinates['LEFT_ELBOW'], coordinates['LEFT_WRIST'])[0],\n",
        "        \"left_elbow_wrist_distance_y\": calc_xy_difference(coordinates['LEFT_ELBOW'], coordinates['LEFT_WRIST'])[1],\n",
        "        \"right_elbow_wrist_distance_x\": calc_xy_difference(coordinates['RIGHT_ELBOW'], coordinates['RIGHT_WRIST'])[0],\n",
        "        \"right_elbow_wrist_distance_y\": calc_xy_difference(coordinates['RIGHT_ELBOW'], coordinates['RIGHT_WRIST'])[1],\n",
        "\n",
        "        # Elbow-Shoulder distance for arms\n",
        "        \"left_elbow_shoulder_distance_x\": calc_xy_difference(coordinates['LEFT_ELBOW'], coordinates['LEFT_SHOULDER'])[0],\n",
        "        \"left_elbow_shoulder_distance_y\": calc_xy_difference(coordinates['LEFT_ELBOW'], coordinates['LEFT_SHOULDER'])[1],\n",
        "        \"right_elbow_shoulder_distance_x\": calc_xy_difference(coordinates['RIGHT_ELBOW'], coordinates['RIGHT_SHOULDER'])[0],\n",
        "        \"right_elbow_shoulder_distance_y\": calc_xy_difference(coordinates['RIGHT_ELBOW'], coordinates['RIGHT_SHOULDER'])[1],\n",
        "\n",
        "        # Shoulder-Hip alignment for left and right sides\n",
        "        \"left_shoulder_hip_alignment_x\": calc_xy_difference(coordinates['LEFT_SHOULDER'], coordinates['LEFT_HIP'])[0],\n",
        "        \"left_shoulder_hip_alignment_y\": calc_xy_difference(coordinates['LEFT_SHOULDER'], coordinates['LEFT_HIP'])[1],\n",
        "        \"right_shoulder_hip_alignment_x\": calc_xy_difference(coordinates['RIGHT_SHOULDER'], coordinates['RIGHT_HIP'])[0],\n",
        "        \"right_shoulder_hip_alignment_y\": calc_xy_difference(coordinates['RIGHT_SHOULDER'], coordinates['RIGHT_HIP'])[1],\n",
        "\n",
        "        # Knee-Ankle distance for legs\n",
        "        \"left_knee_ankle_distance_x\": calc_xy_difference(coordinates['LEFT_KNEE'], coordinates['LEFT_ANKLE'])[0],\n",
        "        \"left_knee_ankle_distance_y\": calc_xy_difference(coordinates['LEFT_KNEE'], coordinates['LEFT_ANKLE'])[1],\n",
        "        \"right_knee_ankle_distance_x\": calc_xy_difference(coordinates['RIGHT_KNEE'], coordinates['RIGHT_ANKLE'])[0],\n",
        "        \"right_knee_ankle_distance_y\": calc_xy_difference(coordinates['RIGHT_KNEE'], coordinates['RIGHT_ANKLE'])[1],\n",
        "\n",
        "        # Knee-Hip distance for legs\n",
        "        \"left_knee_hip_distance_x\": calc_xy_difference(coordinates['LEFT_KNEE'], coordinates['LEFT_HIP'])[0],\n",
        "        \"left_knee_hip_distance_y\": calc_xy_difference(coordinates['LEFT_KNEE'], coordinates['LEFT_HIP'])[1],\n",
        "        \"right_knee_hip_distance_x\": calc_xy_difference(coordinates['RIGHT_KNEE'], coordinates['RIGHT_HIP'])[0],\n",
        "        \"right_knee_hip_distance_y\": calc_xy_difference(coordinates['RIGHT_KNEE'], coordinates['RIGHT_HIP'])[1],\n",
        "\n",
        "        # Wrist-Shoulder distance for arms\n",
        "        \"left_hand_shoulder_distance_x\": calc_xy_difference(coordinates['LEFT_WRIST'], coordinates['LEFT_SHOULDER'])[0],\n",
        "        \"left_hand_shoulder_distance_y\": calc_xy_difference(coordinates['LEFT_WRIST'], coordinates['LEFT_SHOULDER'])[1],\n",
        "        \"right_hand_shoulder_distance_x\": calc_xy_difference(coordinates['RIGHT_WRIST'], coordinates['RIGHT_SHOULDER'])[0],\n",
        "        \"right_hand_shoulder_distance_y\": calc_xy_difference(coordinates['RIGHT_WRIST'], coordinates['RIGHT_SHOULDER'])[1],\n",
        "\n",
        "        # Wrist-Nose distance\n",
        "        \"left_hand_nose_distance_x\": calc_xy_difference(coordinates['LEFT_WRIST'], coordinates['NOSE'])[0],\n",
        "        \"left_hand_nose_distance_y\": calc_xy_difference(coordinates['LEFT_WRIST'], coordinates['NOSE'])[1],\n",
        "        \"right_hand_nose_distance_x\": calc_xy_difference(coordinates['RIGHT_WRIST'], coordinates['NOSE'])[0],\n",
        "        \"right_hand_nose_distance_y\": calc_xy_difference(coordinates['RIGHT_WRIST'], coordinates['NOSE'])[1],\n",
        "\n",
        "        # Wrist-Hip distance\n",
        "        \"left_hand_hip_distance_x\": calc_xy_difference(coordinates['LEFT_WRIST'], coordinates['LEFT_HIP'])[0],\n",
        "        \"left_hand_hip_distance_y\": calc_xy_difference(coordinates['LEFT_WRIST'], coordinates['LEFT_HIP'])[1],\n",
        "        \"right_hand_hip_distance_x\": calc_xy_difference(coordinates['RIGHT_WRIST'], coordinates['RIGHT_HIP'])[0],\n",
        "        \"right_hand_hip_distance_y\": calc_xy_difference(coordinates['RIGHT_WRIST'], coordinates['RIGHT_HIP'])[1],\n",
        "\n",
        "        # Foot spread (left foot index to right foot index)\n",
        "        \"foot_spread_x\": calc_xy_difference(coordinates['LEFT_FOOT_INDEX'], coordinates['RIGHT_FOOT_INDEX'])[0],\n",
        "        \"foot_spread_y\": calc_xy_difference(coordinates['LEFT_FOOT_INDEX'], coordinates['RIGHT_FOOT_INDEX'])[1]\n",
        "    }\n",
        "\n",
        "    return heights\n",
        "\n",
        "\n",
        "def calculate_angle(A, B, C):\n",
        "    \"\"\"\n",
        "    Calculate the angle (in degrees) between vectors AB and BC.\n",
        "    A, B, C are tuples representing (x, y) coordinates.\n",
        "    \"\"\"\n",
        "    # Create vectors AB and BC\n",
        "    AB = np.array([B[0] - A[0], B[1] - A[1]])\n",
        "    BC = np.array([C[0] - B[0], C[1] - B[1]])\n",
        "\n",
        "    # Calculate the dot product and magnitudes (norms) of the vectors\n",
        "    dot_product = np.dot(AB, BC)\n",
        "    magnitude_AB = np.linalg.norm(AB)\n",
        "    magnitude_BC = np.linalg.norm(BC)\n",
        "\n",
        "    # Calculate the cosine of the angle\n",
        "    cos_theta = dot_product / (magnitude_AB * magnitude_BC)\n",
        "\n",
        "    # Handle numerical precision issues (cosine should be between -1 and 1)\n",
        "    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
        "\n",
        "    # Calculate the angle in radians and convert to degrees\n",
        "    angle_rad = np.arccos(cos_theta)\n",
        "    angle_deg = np.degrees(angle_rad)\n",
        "\n",
        "    return angle_deg\n",
        "\n",
        "def create_features_per_excercise(video_folder, excercise_type,mp_pose):\n",
        "    excercise_path = os.path.join(video_folder, excercise_type)  # Construct the full path\n",
        "    vid_count = 0\n",
        "    csv_data = []\n",
        "    if os.path.isdir(excercise_path):  # Ensure it's a directory\n",
        "        for video_file in tqdm(os.listdir(excercise_path)):\n",
        "            video_path = os.path.join(excercise_path, video_file)\n",
        "            # print(f\"Processing video: {video_path}\")\n",
        "\n",
        "            # Open video file\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "            if not cap.isOpened():\n",
        "                print(f\"Error: Could not open video {video_path}.\")\n",
        "                continue\n",
        "            vid_count += 1\n",
        "            frame_number = 0\n",
        "\n",
        "            # Initialize MediaPipe Pose with default settings\n",
        "            with mp_pose.Pose() as pose:\n",
        "                while cap.isOpened():\n",
        "                    ret, frame = cap.read()\n",
        "\n",
        "                    if not ret:\n",
        "                        # print(\"End of video or failed to read frame.\")\n",
        "                        break\n",
        "\n",
        "                    # Convert the frame to RGB (MediaPipe works with RGB images)\n",
        "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                    # Process the frame to detect pose landmarks\n",
        "                    result = pose.process(frame_rgb)\n",
        "\n",
        "                    # Draw pose landmarks if detected\n",
        "                    if result.pose_landmarks:\n",
        "                        for idx, landmark in enumerate(result.pose_landmarks.landmark):\n",
        "                            # print(f\"{mp_pose.PoseLandmark(idx).name}: (x: {landmark.x}, y: {landmark.y}, z: {landmark.z})\")\n",
        "                            csv_data.append([excercise_type,vid_count,frame_number, mp_pose.PoseLandmark(idx).name, landmark.x, landmark.y, landmark.z])\n",
        "                    # Increment frame number\n",
        "                    frame_number += 1\n",
        "            # Release video capture and close all windows\n",
        "            cap.release()\n",
        "            cv2.destroyAllWindows()\n",
        "    return csv_data\n",
        "\n",
        "def feat_to_parquet(csv_data, excercise_name):\n",
        "    df_feat = pd.DataFrame(csv_data)\n",
        "    df_feat = df_feat.rename(columns={\n",
        "        0: 'exc_name',\n",
        "        1: 'vid_num',\n",
        "        2: 'frame',\n",
        "        3: 'landmark',\n",
        "        4: 'x',\n",
        "        5: 'y',\n",
        "        6: 'z'\n",
        "    })\n",
        "    df_feat.to_parquet(f'{excercise_name}_features.parquet')\n",
        "\n",
        "def pad_sequence(sequence_chunk, desired_sequence_length):\n",
        "    num_rows_sequence = sequence_chunk.shape[0]\n",
        "    num_columns_sequence = sequence_chunk.shape[1]\n",
        "\n",
        "    # Determine the label value from the existing sequence\n",
        "    label_value = sequence_chunk['exc_name_encoded'].iloc[0]  # Assumes the label is the same for the whole chunk\n",
        "\n",
        "    # Create an empty sequence with the remaining rows, filled with 0\n",
        "    empty_sequence = pd.DataFrame(\n",
        "        np.full((desired_sequence_length - num_rows_sequence, num_columns_sequence), 0),\n",
        "        columns=sequence_chunk.columns\n",
        "    )\n",
        "\n",
        "    # Set the label column in `empty_sequence` to the correct label\n",
        "    empty_sequence['exc_name_encoded'] = label_value\n",
        "\n",
        "    # Concatenate the original sequence with the padded rows\n",
        "    padded_sequence = pd.concat([sequence_chunk, empty_sequence], axis=0).reset_index(drop=True)\n",
        "\n",
        "    return padded_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8tGjK7LXQIL"
      },
      "outputs": [],
      "source": [
        "# prompt: using calculate_speed check the speed of one landmark in 3d space between two frames 30 frames apart\n",
        "\n",
        "def calculate_speed(frame1_landmarks, frame2_landmarks, frame_num_diff):\n",
        "    \"\"\"\n",
        "    Calculates the speed of body landmarks between two frames.\n",
        "\n",
        "    Args:\n",
        "        frame1_landmarks (dict): Dictionary of landmark coordinates for the first frame.\n",
        "        frame2_landmarks (dict): Dictionary of landmark coordinates for the second frame.\n",
        "        frame_num_diff (int): Difference in frame numbers between the two frames.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the speed of each landmark.\n",
        "              Returns an empty dictionary if input is invalid or landmarks are missing.\n",
        "    \"\"\"\n",
        "\n",
        "    if not isinstance(frame1_landmarks, dict) or not isinstance(frame2_landmarks, dict):\n",
        "        print(\"Error: Input landmarks must be dictionaries.\")\n",
        "        return {}\n",
        "\n",
        "    if not frame_num_diff or frame_num_diff <=0 :\n",
        "      print(\"Error: frame number difference must be positive\")\n",
        "      return {}\n",
        "\n",
        "    speeds = {}\n",
        "    for landmark_name in frame1_landmarks:\n",
        "        if landmark_name in frame2_landmarks:\n",
        "            landmark1 = np.array(frame1_landmarks[landmark_name])\n",
        "            landmark2 = np.array(frame2_landmarks[landmark_name])\n",
        "\n",
        "            if landmark1.size == 3 and landmark2.size == 3:  # Check for 3D coordinates\n",
        "                displacement = np.linalg.norm(landmark2 - landmark1)\n",
        "                speed = displacement / frame_num_diff\n",
        "                speeds[landmark_name] = speed\n",
        "            else:\n",
        "                print(f\"Warning: Skipping landmark '{landmark_name}' - invalid coordinate dimensions.\")\n",
        "        else:\n",
        "            print(f\"Warning: Landmark '{landmark_name}' not found in both frames.\")\n",
        "    return speeds\n",
        "\n",
        "# Example usage (replace with your actual data and frame numbers):\n",
        "#frame_number_1 = 0  # Replace with the actual frame number\n",
        "#frame_number_2 = 30 # Replace with frame 30 frames later\n",
        "\n",
        "# Assuming you have already extracted landmark data into a dictionary for each frame\n",
        "# Sample data below for the example\n",
        "# Replace this with your actual dataframe and extracting the required information.\n",
        "\n",
        "# Call calculate_speed with the landmarks and frame number difference:\n",
        "#landmark_speeds = calculate_speed(frame1_landmarks, frame2_landmarks, 30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: take from df_trail_run the landmarks for a frame. use this frame1_landmarks = {\n",
        "#     'LEFT_SHOULDER': (0.5, 0.6, 0.7),\n",
        "#     'RIGHT_SHOULDER': (0.4, 0.7, 0.5),\n",
        "#     'LEFT_ELBOW': (0.7, 0.3, 0.2)\n",
        "#     # ... other landmarks\n",
        "# }\n",
        "# make a dictionary for each frame with this landmarks:### \"NOSE\",\n",
        "# \"LEFT_SHOULDER\",\n",
        "# \"RIGHT_SHOULDER\",\n",
        "# \"LEFT_ELBOW\",\n",
        "# \"RIGHT_ELBOW\",\n",
        "# \"LEFT_WRIST\",\n",
        "# \"RIGHT_WRIST\",\n",
        "# \"LEFT_HIP\",\n",
        "# \"RIGHT_HIP\",\n",
        "# \"LEFT_KNEE\",\n",
        "# \"RIGHT_KNEE\",\n",
        "# \"LEFT_ANKLE\",\n",
        "# \"RIGHT_ANKLE\",\n",
        "# ###\n",
        "\n",
        "def create_landmark_dict_for_frame(df_trail_run, frame_number):\n",
        "  \"\"\"\n",
        "  Creates a dictionary of landmark coordinates for a given frame from the dataframe.\n",
        "\n",
        "  Args:\n",
        "      df_trail_run (pd.DataFrame): The dataframe containing landmark data.\n",
        "      frame_number (int): The frame number to extract landmarks for.\n",
        "\n",
        "  Returns:\n",
        "      dict: A dictionary where keys are landmark names and values are (x, y, z) tuples.\n",
        "  \"\"\"\n",
        "\n",
        "  df_frame = df_trail_run[df_trail_run['frame'] == frame_number]\n",
        "  landmarks = {}\n",
        "  for landmark_name in ['NOSE', 'LEFT_SHOULDER', 'RIGHT_SHOULDER', 'LEFT_ELBOW', 'RIGHT_ELBOW', 'LEFT_WRIST', 'RIGHT_WRIST', 'LEFT_HIP', 'RIGHT_HIP', 'LEFT_KNEE', 'RIGHT_KNEE', 'LEFT_ANKLE', 'RIGHT_ANKLE']:\n",
        "    if not df_frame[df_frame['landmark'] == landmark_name].empty:\n",
        "        x = df_frame[df_frame['landmark'] == landmark_name]['x'].values[0]\n",
        "        y = df_frame[df_frame['landmark'] == landmark_name]['y'].values[0]\n",
        "        z = df_frame[df_frame['landmark'] == landmark_name]['z'].values[0]\n",
        "        landmarks[landmark_name] = (x, y, z)\n",
        "  return landmarks\n",
        "\n"
      ],
      "metadata": {
        "id": "5umwudIaXbvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y51vNWhy_sXJ"
      },
      "source": [
        "## Initial Mediapipe Trial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Wev6L2_sXJ"
      },
      "source": [
        "### Run landmark detection on a video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8Ng9eFd_sXK"
      },
      "outputs": [],
      "source": [
        "# Initialize MediaPipe Pose and Drawing modules\n",
        "mp_pose = mp.solutions.pose\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# Video capture path (ensure it points to your video correctly)\n",
        "video_path = r'/content/drive/MyDrive/videos_for_project/first_long_video_perperson.mp4'\n",
        "excercise_type_temp = 'good fall'\n",
        "vid_count_temp = 2\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "print(f'Total number of frames: {frame_count}')\n",
        "\n",
        "# Get the frames per second (FPS)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "print(f'Frames per second (FPS): {fps}')\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(f\"Error: Could not open video {video_path}.\")\n",
        "    exit()\n",
        "\n",
        "frame_number = 0\n",
        "csv_data = []\n",
        "landmark_lst = []\n",
        "\n",
        "# Initialize MediaPipe Pose with default settings\n",
        "with mp_pose.Pose() as pose:\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"End of video or failed to read frame.\")\n",
        "            break\n",
        "\n",
        "        # Convert the frame to RGB (MediaPipe works with RGB images)\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Process the frame to detect pose landmarks\n",
        "        result = pose.process(frame_rgb)\n",
        "\n",
        "        # Draw pose landmarks if detected\n",
        "        if result.pose_landmarks:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                frame, result.pose_landmarks, mp_pose.POSE_CONNECTIONS\n",
        "            )\n",
        "\n",
        "            frame_landmarks = result.pose_landmarks.landmark\n",
        "            right_shoulder = (frame_landmarks[12].x,frame_landmarks[12].y)\n",
        "            right_elbow = (frame_landmarks[14].x,frame_landmarks[14].y)\n",
        "            right_wrist = (frame_landmarks[16].x,frame_landmarks[16].y)\n",
        "            frame_angle = -(calculate_angle(right_wrist, right_elbow, right_shoulder) - 180)\n",
        "\n",
        "            # Optional: Add landmark coordinates to CSV data\n",
        "            for idx, landmark in enumerate(result.pose_landmarks.landmark):\n",
        "                # print(f\"{mp_pose.PoseLandmark(idx).name}: (x: {landmark.x}, y: {landmark.y}, z: {landmark.z})\")\n",
        "                csv_data.append([excercise_type_temp,vid_count_temp,frame_number, mp_pose.PoseLandmark(idx).name, landmark.x, landmark.y, landmark.z])\n",
        "            landmark_lst.append(result.pose_landmarks)\n",
        "\n",
        "            # Add text to the frame\n",
        "        # text = f\"Angle {round(frame_angle,2)}\"\n",
        "        # org = (50, 50)  # Coordinates for the text (x, y)\n",
        "        # font = cv2.FONT_HERSHEY_SIMPLEX  # Font type\n",
        "        # fontScale = 1  # Font size\n",
        "        # color = (0, 255, 0)  # Green text in BGR\n",
        "        # thickness = 2  # Thickness of the text\n",
        "        # lineType = cv2.LINE_AA  # Anti-aliased text\n",
        "\n",
        "        # # Write the text on the frame\n",
        "        # cv2.putText(frame, text, org, font, fontScale, color, thickness, lineType)\n",
        "\n",
        "\n",
        "        # cv2.putText(frame, frame_angle)\n",
        "        # Display the frame in a window\n",
        "        # cv2_imshow(frame)\n",
        "\n",
        "        # Increment frame number\n",
        "        frame_number += 1\n",
        "\n",
        "        # Wait for 1ms and exit if 'q' is pressed\n",
        "        #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        #    break\n",
        "\n",
        "    # Release video capture and close all windows\n",
        "    cap.release()\n",
        "    #cv2.destroyAllWindows()\n",
        "    print(\"Video processing complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### write to drive"
      ],
      "metadata": {
        "id": "ib7uMrgE4mLl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMccneYA4f3U"
      },
      "outputs": [],
      "source": [
        "# Specify the path where you want to save the CSV file in your Google Drive\n",
        "csv_file_path = '/content/drive/MyDrive/videos_for_project/csv_data/pose_landmarks_first_long_video.csv'\n",
        "\n",
        "# Write the data to the CSV file\n",
        "with open(csv_file_path, 'w', newline='') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    # Write the header row (if needed)\n",
        "    csv_writer.writerow(['exc_name', 'vid_num', 'frame', 'landmark', 'x', 'y', 'z'])\n",
        "    csv_writer.writerows(csv_data)\n",
        "\n",
        "print(f\"CSV data saved to: {csv_file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### read from drive"
      ],
      "metadata": {
        "id": "iD7NuCcF4ct3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_data = pd.read_csv('/content/drive/MyDrive/videos_for_project/csv_data/pose_landmarks_first_long_video.csv')"
      ],
      "metadata": {
        "id": "1VYHNIHY4BKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe8xMSjZ_sXK"
      },
      "source": [
        "### Collect data for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLNVx6FP_sXK"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_trail_run = pd.DataFrame(csv_data)\n",
        "# Rename the columns from 0-5 to meaningful names\n",
        "df_trail_run = df_trail_run.rename(columns={\n",
        "    0: 'exc_name',\n",
        "    1: 'vid_num',\n",
        "    2: 'frame',\n",
        "    3: 'landmark',\n",
        "    4: 'x',\n",
        "    5: 'y',\n",
        "    6: 'z'\n",
        "})\n",
        "df_trail_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTn__nVN_sXL"
      },
      "outputs": [],
      "source": [
        "# Look at what one frame looks like\n",
        "df_trail_run[df_trail_run['frame'] == 200]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XGkzwdq_sXL"
      },
      "source": [
        "### Look at angles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXbVJb6d9tez"
      },
      "source": [
        "right elbow angle over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqN7SMJE_sXL"
      },
      "outputs": [],
      "source": [
        "frame_angles = []\n",
        "for frame_num in np.unique(df_trail_run['frame']):\n",
        "    right_elbow = (df_trail_run[(df_trail_run['frame'] == frame_num) & (df_trail_run['landmark'] == 'RIGHT_ELBOW')].x.values[0], df_trail_run[(df_trail_run['frame'] == frame_num) & (df_trail_run['landmark'] == 'RIGHT_ELBOW')].y.values[0])\n",
        "    right_shoulder = (df_trail_run[(df_trail_run['frame'] == frame_num) & (df_trail_run['landmark'] == 'RIGHT_SHOULDER')].x.values[0],df_trail_run[(df_trail_run['frame'] == frame_num) & (df_trail_run['landmark'] == 'RIGHT_SHOULDER')].y.values[0])\n",
        "    right_wrist = (df_trail_run[(df_trail_run['frame'] == frame_num) & (df_trail_run['landmark'] == 'RIGHT_WRIST')].x.values[0],df_trail_run[(df_trail_run['frame'] == frame_num) & (df_trail_run['landmark'] == 'RIGHT_WRIST')].y.values[0])\n",
        "    frame_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
        "    frame_angles.append(frame_angle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySR4cA7w_sXL"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(len(frame_angles)),frame_angles)\n",
        "plt.xlabel('Frame Number')\n",
        "plt.ylabel('Angle')\n",
        "plt.title('Angle Over Time')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFWJcfmm_sXL"
      },
      "source": [
        "### Working with the landmark list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC_b6n6F_sXL"
      },
      "outputs": [],
      "source": [
        "right_shoulder = (landmark_lst[0].landmark[12].x,landmark_lst[0].landmark[12].y)\n",
        "right_elbow = (landmark_lst[0].landmark[14].x,landmark_lst[0].landmark[14].y)\n",
        "right_wrist = (landmark_lst[0].landmark[16].x,landmark_lst[0].landmark[16].y)\n",
        "frame_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
        "frame_angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fXgleu_B0dp"
      },
      "outputs": [],
      "source": [
        "# prompt: using  the landmark list and the helper function calculate_body_angles(). make a table of all the body angles in all frames and save it to my drive\n",
        "\n",
        "# LANDMARKS is already defined globally\n",
        "\n",
        "# Create an empty list to store angle data\n",
        "all_body_angles = []\n",
        "\n",
        "# Iterate over unique frames in the DataFrame\n",
        "for frame_num in tqdm(np.unique(df_trail_run['frame']), desc=\"Processing frames\"):\n",
        "    df_frame = df_trail_run[df_trail_run['frame'] == frame_num]\n",
        "\n",
        "    # Retrieve coordinates for all landmarks in a dictionary\n",
        "    coordinates = {landmark: get_coords(landmark, df_frame) for landmark in LANDMARKS}\n",
        "\n",
        "    # Calculate body vectors using the coordinates\n",
        "    vectors = get_body_vecs(coordinates)\n",
        "\n",
        "    # Calculate frame angles using the vectors\n",
        "    frame_angles = calculate_body_angles(vectors)\n",
        "\n",
        "    frame_angles['frame'] = frame_num\n",
        "    all_body_angles.append(frame_angles)\n",
        "\n",
        "# Convert to dataframe and save\n",
        "angle_df = pd.DataFrame(all_body_angles)\n",
        "angle_df.to_csv('/content/drive/MyDrive/body_angles_first_long_video.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBYMhpYW_sXM"
      },
      "source": [
        "### 3d plot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###read csv data from file and DBSCAN to detect fall in frames"
      ],
      "metadata": {
        "id": "KZnZAX3TumZy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5Skvya-YjDb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# קריאת הנתונים\n",
        "file_path = \"/content/drive/MyDrive/videos_for_project/csv_data/body_angles_first_long_video.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# הסרת עמודת ה-frame לצורך עיבוד\n",
        "frame_col = df['frame']  # שמירת מספרי הפריימים\n",
        "features = df.drop(columns=['frame'])\n",
        "\n",
        "# נורמליזציה של הנתונים\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "\n",
        "dbscan = DBSCAN(eps=0.9, min_samples=5)\n",
        "df['cluster'] = dbscan.fit_predict(features_scaled)\n",
        "\n",
        "# סינון הנתונים כך שנראה רק את הקבוצות -1 (חריגים) ו-0\n",
        "df_filtered = df[df['cluster'].isin([-1, 0])]\n",
        "\n",
        "# שחזור עמודת ה-frame\n",
        "df['frame'] = frame_col\n",
        "\n",
        "# איתור פריימים שבהם התחולל מעבר בין עמידה לרצפה (או להפך)\n",
        "df['transition'] = df['cluster'].diff().abs().fillna(0)\n",
        "transition_frames = df[df['transition'] == 1]['frame'].tolist()\n",
        "\n",
        "# הצגת פריימים שבהם התחולל מעבר בין מצבים\n",
        "print(\"Transition Frames (Fall Start Detected):\", transition_frames)\n",
        "\n",
        "# ויזואליזציה - הצגת הזוויות בפריימים מסודרים לפי הזמן\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(\n",
        "    x=df_filtered[\"frame\"], y=df_filtered[\"cluster\"],\n",
        "    hue=df_filtered[\"cluster\"], palette=[\"red\", \"blue\"], alpha=0.7\n",
        ")\n",
        "plt.xlabel(\"Frame\")\n",
        "plt.ylabel(\"Cluster (-1=Outlier/Fall, 0=Standing)\")\n",
        "plt.title(\"DBSCAN Clustering: Detecting Falls (-1) vs. Standing (0)\")\n",
        "plt.legend(title=\"Cluster\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cARzpNPLJQCx"
      },
      "outputs": [],
      "source": [
        "df_filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpo2EIiU_sXM"
      },
      "source": [
        "#### Initial 3d plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAnWg-6e_sXM"
      },
      "outputs": [],
      "source": [
        "# Initialize MediaPipe Pose module\n",
        "mp_pose = mp.solutions.pose\n",
        "POSE_CONNECTIONS = mp_pose.POSE_CONNECTIONS\n",
        "frame_number = 5\n",
        "\n",
        "# Filter the data for the desired frame\n",
        "df_frame = df_trail_run[df_trail_run['frame'] == frame_number]\n",
        "\n",
        "prediction = df_filtered[df_filtered['frame'] == frame_number]['cluster'].values[0]\n",
        "\n",
        "# Create a dictionary mapping landmark names to their (x, y, z) coordinates\n",
        "landmarks = {row['landmark']: (row['x'], row['y'], row['z']) for _, row in df_frame.iterrows()}\n",
        "\n",
        "# Initialize the 3D plot\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot landmarks as scatter points\n",
        "for name, (x, y, z) in landmarks.items():\n",
        "    ax.scatter(-z, x, y, label=name, s=50)  # Adjusting axes to align with desired orientation\n",
        "\n",
        "# Helper function to get coordinates by landmark name\n",
        "def get_coord(name):\n",
        "    \"\"\"Returns the (x, y, z) coordinates of a given landmark.\"\"\"\n",
        "    return landmarks.get(name, (None, None, None))\n",
        "\n",
        "# Plot lines connecting the landmarks using POSE_CONNECTIONS\n",
        "for connection in POSE_CONNECTIONS:\n",
        "    start, end = connection\n",
        "    start_name = mp_pose.PoseLandmark(start).name\n",
        "    end_name = mp_pose.PoseLandmark(end).name\n",
        "\n",
        "    # Get the coordinates of the two landmarks\n",
        "    start_coord = get_coord(start_name)\n",
        "    end_coord = get_coord(end_name)\n",
        "\n",
        "    # Check if both landmarks are available\n",
        "    if None not in start_coord and None not in end_coord:\n",
        "        ax.plot(\n",
        "            [-start_coord[2], -end_coord[2]],  # x-coordinates\n",
        "            [start_coord[0], end_coord[0]],    # y-coordinates\n",
        "            [start_coord[1], end_coord[1]],    # z-coordinates\n",
        "            color='blue'\n",
        "        )\n",
        "\n",
        "# Set axis labels\n",
        "ax.set_zlabel('y')\n",
        "ax.set_xlabel('z')\n",
        "ax.set_ylabel('x')\n",
        "\n",
        "# Flip the Z-axis to ensure head is at the top and legs at the bottom\n",
        "ax.invert_zaxis()\n",
        "\n",
        "# Rotate, tilt, and twist the graph\n",
        "ax.view_init(elev=10, azim=20)  # Adjust 'elev' and 'azim' as needed\n",
        "\n",
        "# Set plot title\n",
        "plt.title(f'3D Pose for Frame {frame_number} prediction: {prediction}')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENjvRSFp_sXM"
      },
      "source": [
        "#### Interactive 3d plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hZx1tlB_sXN"
      },
      "outputs": [],
      "source": [
        "# Initialize MediaPipe Pose module\n",
        "mp_pose = mp.solutions.pose\n",
        "POSE_CONNECTIONS = mp_pose.POSE_CONNECTIONS\n",
        "frame_number = 161\n",
        "\n",
        "# Filter the data for the desired frame\n",
        "df_frame = df_trail_run[df_trail_run['frame'] == frame_number]\n",
        "\n",
        "# Create a dictionary mapping landmark names to their (x, y, z) coordinates\n",
        "landmarks = {row['landmark']: (row['x'], row['y'], row['z']) for _, row in df_frame.iterrows()}\n",
        "\n",
        "# Prepare lists to store points and connections\n",
        "x_vals, y_vals, z_vals, names = [], [], [], []\n",
        "\n",
        "# Collect the landmarks for plotting\n",
        "for name, (x, y, z) in landmarks.items():\n",
        "    x_vals.append(x)\n",
        "    y_vals.append(y)\n",
        "    z_vals.append(z)\n",
        "    names.append(name)\n",
        "\n",
        "# Create a 3D scatter plot for landmarks\n",
        "scatter = go.Scatter3d(\n",
        "    x=x_vals, y=z_vals, z=y_vals,  # Swap axes to align with your desired orientation\n",
        "    mode='markers+text',\n",
        "    marker=dict(size=5, color='blue'),\n",
        "    text=names,  # Show names as text labels\n",
        "    textposition=\"top center\"\n",
        ")\n",
        "\n",
        "# Create line segments for each connection\n",
        "connections = []\n",
        "for connection in POSE_CONNECTIONS:\n",
        "    start, end = connection\n",
        "    start_name = mp_pose.PoseLandmark(start).name\n",
        "    end_name = mp_pose.PoseLandmark(end).name\n",
        "\n",
        "    start_coord = landmarks.get(start_name, None)\n",
        "    end_coord = landmarks.get(end_name, None)\n",
        "\n",
        "    # Ensure both landmarks exist\n",
        "    if start_coord and end_coord:\n",
        "        connections.append(\n",
        "            go.Scatter3d(\n",
        "                x=[start_coord[0], end_coord[0]],\n",
        "                y=[start_coord[2], end_coord[2]],  # Swap Y and Z axes\n",
        "                z=[start_coord[1], end_coord[1]],\n",
        "                mode='lines',\n",
        "                line=dict(color='blue', width=2)\n",
        "            )\n",
        "        )\n",
        "\n",
        "# Combine scatter plot and connections into a figure\n",
        "fig = go.Figure(data=[scatter] + connections)\n",
        "\n",
        "# Set axis labels and layout\n",
        "fig.update_layout(\n",
        "    scene=dict(\n",
        "        xaxis_title='X',\n",
        "        yaxis_title='Z',\n",
        "        zaxis_title='Y',\n",
        "        zaxis=dict(autorange='reversed')  # Ensure head is at the top and legs at the bottom\n",
        "    ),\n",
        "    title=f\"3D Pose for Frame {frame_number}\",\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "# Display the interactive plot\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###create a dataframe with the landmarks as columns and the speed as rows. add the speed for every frame as a row"
      ],
      "metadata": {
        "id": "IQe0UzFLXolB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a dataframe with the landmarks as columns and the speed as rows. add the speed for every frame as a row\n",
        "\n",
        "# Assuming you have the necessary variables and functions defined (like LANDMARKS, df_trail_run)\n",
        "\n",
        "# Create an empty list to store speed data for each frame\n",
        "all_landmark_speeds = []\n",
        "\n",
        "# Iterate through frames, calculating speed between consecutive frames\n",
        "for frame_num in tqdm(range(len(np.unique(df_trail_run['frame'])) - 1), desc=\"Calculating speeds\"):\n",
        "  frame1_landmarks = create_landmark_dict_for_frame(df_trail_run, frame_num)\n",
        "  frame2_landmarks = create_landmark_dict_for_frame(df_trail_run, frame_num + 30)\n",
        "\n",
        "  landmark_speeds = calculate_speed(frame1_landmarks, frame2_landmarks, 30)  # Frame difference is 30\n",
        "\n",
        "  landmark_speeds['frame'] = frame_num\n",
        "  frame_num = frame_num + 30\n",
        "  all_landmark_speeds.append(landmark_speeds)\n",
        "\n",
        "\n",
        "# Convert to DataFrame\n",
        "speed_df = pd.DataFrame(all_landmark_speeds)\n",
        "\n",
        "# Reorder columns so 'frame' is first\n",
        "cols = speed_df.columns.tolist()\n",
        "cols.remove('frame')\n",
        "speed_df = speed_df[['frame'] + cols]\n",
        "\n",
        "# Display the DataFrame (optional)\n",
        "speed_df\n"
      ],
      "metadata": {
        "id": "xG6-ooGzP3Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZbQqJqTVu0z"
      },
      "outputs": [],
      "source": [
        "# Specify the path where you want to save the CSV file in your Google Drive\n",
        "csv_file_path = '/content/drive/MyDrive/videos_for_project/csv_data/speeds_landmarks_first_long_video.csv'\n",
        "\n",
        "# Write the data to the CSV file\n",
        "with open(csv_file_path, 'w', newline='') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    # Write the header row (if needed)\n",
        "    csv_writer.writerow(speed_df.columns)\n",
        "    # Write the data rows\n",
        "    csv_writer.writerows(speed_df.values)\n",
        "\n",
        "print(f\"CSV data saved to: {csv_file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Using dataframe speed_df: view one landmark as a graph when x is time y is speed\n",
        "\n",
        "# Import necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select a specific landmark (e.g., 'NOSE') and plot its speed over time\n",
        "landmark_name = 'LEFT_WRIST'\n",
        "\n",
        "# Assuming 'frame' represents time and the landmark column represents speed\n",
        "plt.plot(speed_df['frame'], speed_df[landmark_name])\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Time (frame)')\n",
        "plt.ylabel('Speed')\n",
        "plt.title(f'Speed of {landmark_name} Over Time')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0s722ll9Rz4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: from the dataframe speed_df calculate the acceleration of each landmark\n",
        "\n",
        "# Calculate acceleration for each landmark\n",
        "acceleration_df = speed_df.copy()\n",
        "for landmark in speed_df.columns[1:]:\n",
        "  acceleration_df[landmark + '_acceleration'] = acceleration_df[landmark].diff()\n",
        "\n",
        "# Display the DataFrame with acceleration (optional)\n",
        "acceleration_df\n"
      ],
      "metadata": {
        "id": "zCL840qcYKJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: make  plot for one landmark speed and acceleration\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Select a specific landmark (e.g., 'NOSE') and plot its speed and acceleration over time\n",
        "landmark_name = 'LEFT_WRIST'\n",
        "\n",
        "# Assuming 'frame' represents time and the landmark column represents speed\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(speed_df['frame'], speed_df[landmark_name], label='Speed')\n",
        "plt.plot(acceleration_df['frame'], acceleration_df[landmark_name + '_acceleration'], label='Acceleration')\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Time (frame)')\n",
        "plt.ylabel('Speed / Acceleration')\n",
        "plt.title(f'Speed and Acceleration of {landmark_name} Over Time')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DKHuU6pAaLjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtvG8UT6ckCW"
      },
      "outputs": [],
      "source": [
        "\n",
        "# קריאת הנתונים\n",
        "#file_path = \"/content/drive/MyDrive/videos_for_project/csv_data/body_angles_first_long_video.csv\"\n",
        "#df = pd.read_csv(file_path)\n",
        "df = speed_df\n",
        "# הסרת עמודת ה-frame לצורך עיבוד\n",
        "frame_col = df['frame']  # שמירת מספרי הפריימים\n",
        "features = df.drop(columns=['frame'])\n",
        "# remove NaN\n",
        "features = features.fillna(0)\n",
        "\n",
        "# נורמליזציה של הנתונים\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "\n",
        "dbscan = DBSCAN(eps=0.9, min_samples=5)\n",
        "df['cluster'] = dbscan.fit_predict(features_scaled)\n",
        "\n",
        "# סינון הנתונים כך שנראה רק את הקבוצות -1 (חריגים) ו-0\n",
        "df_filtered = df[df['cluster'].isin([-1, 0])]\n",
        "\n",
        "# שחזור עמודת ה-frame\n",
        "df['frame'] = frame_col\n",
        "\n",
        "# איתור פריימים שבהם התחולל מעבר בין עמידה לרצפה (או להפך)\n",
        "df['transition'] = df['cluster'].diff().abs().fillna(0)\n",
        "transition_frames = df[df['transition'] == 1]['frame'].tolist()\n",
        "\n",
        "# הצגת פריימים שבהם התחולל מעבר בין מצבים\n",
        "print(\"Transition Frames (Fall Start Detected):\", transition_frames)\n",
        "\n",
        "# ויזואליזציה - הצגת הזוויות בפריימים מסודרים לפי הזמן\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(\n",
        "    x=df_filtered[\"frame\"], y=df_filtered[\"cluster\"],\n",
        "    hue=df_filtered[\"cluster\"], palette=[\"red\", \"blue\"], alpha=0.7\n",
        ")\n",
        "plt.xlabel(\"Frame\")\n",
        "plt.ylabel(\"Cluster (-1=Outlier/Fall, 0=Standing)\")\n",
        "plt.title(\"DBSCAN Clustering: Detecting Falls (-1) vs. Standing (0)\")\n",
        "plt.legend(title=\"Cluster\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### fall detection from body angles and speeds"
      ],
      "metadata": {
        "id": "veDPO3QHUnBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "body_angles_path =\"/content/drive/MyDrive/videos_for_project/csv_data/first long video/body_angles_first_long_video.csv\"\n",
        "body_speeds_path =\"/content/drive/MyDrive/videos_for_project/csv_data/first long video/speeds_landmarks_first_long_video.csv\"\n",
        "landmarks_path =\"/content/drive/MyDrive/videos_for_project/csv_data/first long video/pose_landmarks_first_long_video.csv\""
      ],
      "metadata": {
        "id": "ngSHaRjzR_eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "\n",
        "def detect_falls(angles_path, speeds_path, landmarks_path, intensity_threshold_first_half=180,\n",
        "                 intensity_threshold_second_half=200, min_falls=8, max_falls=12):\n",
        "    # Load data\n",
        "    angles_df = pd.read_csv(angles_path)\n",
        "    speeds_df = pd.read_csv(speeds_path)\n",
        "    landmarks_df = pd.read_csv(landmarks_path)\n",
        "\n",
        "    # Merge datasets\n",
        "    merged_df = angles_df.merge(speeds_df, on=\"frame\", how=\"inner\")\n",
        "    landmarks_filtered = landmarks_df[['frame']].drop_duplicates()\n",
        "    final_df = merged_df.merge(landmarks_filtered, on=\"frame\", how=\"inner\")\n",
        "\n",
        "    # Handle missing values\n",
        "    final_df.fillna(final_df.mean(), inplace=True)\n",
        "\n",
        "    # Compute movement intensity\n",
        "    movement_diff = final_df.drop(columns=['frame']).diff().abs().sum(axis=1)\n",
        "    final_df['movement_intensity'] = movement_diff\n",
        "\n",
        "    # Predict fall frames based on intensity\n",
        "    predicted_fall_frames = final_df[final_df['movement_intensity'] > min(intensity_threshold_first_half,\n",
        "                                                                          intensity_threshold_second_half)]['frame'].values\n",
        "\n",
        "    # Split frames by first and second half\n",
        "    mid_frame = final_df['frame'].median()\n",
        "    first_half = predicted_fall_frames[predicted_fall_frames < mid_frame]\n",
        "    second_half = predicted_fall_frames[predicted_fall_frames >= mid_frame]\n",
        "\n",
        "    # Filter based on respective intensity thresholds\n",
        "    first_half_filtered = [f for f in first_half if final_df.loc[f, 'movement_intensity'] > intensity_threshold_first_half]\n",
        "    second_half_filtered = [f for f in second_half if final_df.loc[f, 'movement_intensity'] > intensity_threshold_second_half]\n",
        "    all_filtered = np.array(first_half_filtered + second_half_filtered).reshape(-1, 1)\n",
        "\n",
        "    # Cluster fall frames\n",
        "    def find_optimal_threshold(frames, min_falls, max_falls):\n",
        "        for t in np.linspace(150, 20, 20):\n",
        "            Z = linkage(frames, method='ward')\n",
        "            clusters = fcluster(Z, t=t, criterion='distance')\n",
        "            if min_falls <= len(np.unique(clusters)) <= max_falls:\n",
        "                return clusters\n",
        "        return fcluster(Z, t=50, criterion='distance')\n",
        "\n",
        "    if len(all_filtered) > 1:\n",
        "        clusters = find_optimal_threshold(all_filtered, min_falls, max_falls)\n",
        "        clustered_df = pd.DataFrame({'frame': all_filtered.flatten(), 'cluster': clusters})\n",
        "        fall_starts = clustered_df.groupby('cluster')['frame'].min().sort_values().reset_index(drop=True)\n",
        "    else:\n",
        "        fall_starts = pd.Series([], dtype=int)\n",
        "\n",
        "    return fall_starts\n",
        "\n",
        "# Example usage:\n",
        "# fall_frames = detect_falls(\"body_angles.csv\", \"body_speeds.csv\", \"landmarks.csv\")\n",
        "# fall_frames.to_csv(\"refined_fall_detection_results.csv\", index=False)\n",
        "\n",
        "fall_frames = detect_falls(body_angles_path, body_speeds_path, landmarks_path,intensity_threshold_second_half=100)\n",
        "#fall_frames.to_csv(\"refined_fall_detection_results.csv\", index=False)\n",
        "fall_frames"
      ],
      "metadata": {
        "id": "BIRCtYN0RQbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_trail_run = pd.read_csv(landmarks_path)"
      ],
      "metadata": {
        "id": "42X7N6c2WSoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rU_8N7MOWS4X"
      },
      "outputs": [],
      "source": [
        "# Initialize MediaPipe Pose module\n",
        "mp_pose = mp.solutions.pose\n",
        "POSE_CONNECTIONS = mp_pose.POSE_CONNECTIONS\n",
        "frame_number = 98\n",
        "\n",
        "# Filter the data for the desired frame\n",
        "df_frame = df_trail_run[df_trail_run['frame'] == frame_number]\n",
        "\n",
        "# Create a dictionary mapping landmark names to their (x, y, z) coordinates\n",
        "landmarks = {row['landmark']: (row['x'], row['y'], row['z']) for _, row in df_frame.iterrows()}\n",
        "\n",
        "# Initialize the 3D plot\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot landmarks as scatter points\n",
        "for name, (x, y, z) in landmarks.items():\n",
        "    ax.scatter(-z, x, y, label=name, s=50)  # Adjusting axes to align with desired orientation\n",
        "\n",
        "# Helper function to get coordinates by landmark name\n",
        "def get_coord(name):\n",
        "    \"\"\"Returns the (x, y, z) coordinates of a given landmark.\"\"\"\n",
        "    return landmarks.get(name, (None, None, None))\n",
        "\n",
        "# Plot lines connecting the landmarks using POSE_CONNECTIONS\n",
        "for connection in POSE_CONNECTIONS:\n",
        "    start, end = connection\n",
        "    start_name = mp_pose.PoseLandmark(start).name\n",
        "    end_name = mp_pose.PoseLandmark(end).name\n",
        "\n",
        "    # Get the coordinates of the two landmarks\n",
        "    start_coord = get_coord(start_name)\n",
        "    end_coord = get_coord(end_name)\n",
        "\n",
        "    # Check if both landmarks are available\n",
        "    if None not in start_coord and None not in end_coord:\n",
        "        ax.plot(\n",
        "            [-start_coord[2], -end_coord[2]],  # x-coordinates\n",
        "            [start_coord[0], end_coord[0]],    # y-coordinates\n",
        "            [start_coord[1], end_coord[1]],    # z-coordinates\n",
        "            color='blue'\n",
        "        )\n",
        "\n",
        "# Set axis labels\n",
        "ax.set_zlabel('y')\n",
        "ax.set_xlabel('z')\n",
        "ax.set_ylabel('x')\n",
        "\n",
        "# Flip the Z-axis to ensure head is at the top and legs at the bottom\n",
        "ax.invert_zaxis()\n",
        "\n",
        "# Rotate, tilt, and twist the graph\n",
        "ax.view_init(elev=10, azim=20)  # Adjust 'elev' and 'azim' as needed\n",
        "\n",
        "# Set plot title\n",
        "plt.title(f'3D Pose for Frame {frame_number}')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P8i2Y1p_sXN"
      },
      "source": [
        "#### Turn 3d plot into movie with multiple frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I_6kcGa_sXN"
      },
      "outputs": [],
      "source": [
        "# Initialize MediaPipe Pose module\n",
        "mp_pose = mp.solutions.pose\n",
        "POSE_CONNECTIONS = mp_pose.POSE_CONNECTIONS\n",
        "\n",
        "# Create a directory to store individual frame images\n",
        "os.makedirs('frames', exist_ok=True)\n",
        "\n",
        "# Determine the overall min and max values across all frames to set consistent axis limits\n",
        "x_min, x_max = df_trail_run['x'].min(), df_trail_run['x'].max()\n",
        "y_min, y_max = df_trail_run['y'].min(), df_trail_run['y'].max()\n",
        "z_min, z_max = df_trail_run['z'].min(), df_trail_run['z'].max()\n",
        "\n",
        "def get_coord(name, landmarks):\n",
        "    \"\"\"Returns the (x, y, z) coordinates of a given landmark.\"\"\"\n",
        "    return landmarks.get(name, (None, None, None))\n",
        "\n",
        "# Generate and save plots for each frame\n",
        "for frame_number in range(df_trail_run['frame'].max() + 1):\n",
        "    # Filter the data for the desired frame\n",
        "    df_trail_run_frame = df_trail_run[df_trail_run['frame'] == frame_number]\n",
        "\n",
        "    if df_trail_run_frame.empty:\n",
        "      # Handle the case where there are no predictions for this frame\n",
        "      # You might want to skip this frame, assign a default value, or raise an exception\n",
        "      print(f\"Warning: No predictions found for frame {frame_number}. Skipping this frame.\")\n",
        "      continue  # Skip to the next frame\n",
        "    prediction = df[df['frame'] == frame_number]['cluster'].values[0]\n",
        "\n",
        "\n",
        "\n",
        "    # Create a dictionary mapping landmark names to their (x, y, z) coordinates\n",
        "    landmarks = {row['landmark']: (row['x'], row['y'], row['z']) for _, row in df_trail_run_frame.iterrows()}\n",
        "\n",
        "    # Initialize the 3D plot\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Plot landmarks as scatter points\n",
        "    for name, (x, y, z) in landmarks.items():\n",
        "        ax.scatter(-z, x, y, label=name, s=50)  # Adjusting axes to align with desired orientation\n",
        "\n",
        "    # Plot lines connecting the landmarks using POSE_CONNECTIONS\n",
        "    for connection in POSE_CONNECTIONS:\n",
        "        start, end = connection\n",
        "        start_name = mp_pose.PoseLandmark(start).name\n",
        "        end_name = mp_pose.PoseLandmark(end).name\n",
        "\n",
        "        start_coord = get_coord(start_name, landmarks)\n",
        "        end_coord = get_coord(end_name, landmarks)\n",
        "\n",
        "        # Check if both landmarks are available\n",
        "        if None not in start_coord and None not in end_coord:\n",
        "            ax.plot(\n",
        "                [-start_coord[2], -end_coord[2]],  # x-coordinates\n",
        "                [start_coord[0], end_coord[0]],    # y-coordinates\n",
        "                [start_coord[1], end_coord[1]],    # z-coordinates\n",
        "                color='blue'\n",
        "            )\n",
        "\n",
        "    # Set consistent axis limits\n",
        "    ax.set_xlim([-z_max, -z_min])\n",
        "    ax.set_ylim([x_min, x_max])\n",
        "    ax.set_zlim([y_min, y_max])\n",
        "\n",
        "    # Set axis labels\n",
        "    ax.set_xlabel('Z')\n",
        "    ax.set_ylabel('X')\n",
        "    ax.set_zlabel('Y')\n",
        "\n",
        "    # Flip the Z-axis to ensure head is at the top and legs at the bottom\n",
        "    ax.invert_zaxis()\n",
        "\n",
        "    # Maintain aspect ratio\n",
        "    ax.set_box_aspect([1, 1, 1])  # Same scaling for all axes\n",
        "\n",
        "    # Rotate, tilt, and twist the graph\n",
        "    ax.view_init(elev=10, azim=20)  # Adjust 'elev' and 'azim' as needed\n",
        "\n",
        "    # Set plot title\n",
        "    plt.title(f'3D Pose for Frame {frame_number} prediction: {prediction}')\n",
        "\n",
        "\n",
        "    # Save the plot as an image\n",
        "    filename = f'frames/frame_{frame_number:03d}.png'\n",
        "    plt.savefig(filename)\n",
        "    plt.close(fig)  # Close the figure to free memory\n",
        "\n",
        "# Create a video from the saved images\n",
        "with imageio.get_writer('pose_video_with_prediction.mp4', fps=10) as writer:\n",
        "    for frame_number in range(df_trail_run['frame'].max() + 1):\n",
        "        filename = f'frames/frame_{frame_number:03d}.png'\n",
        "        if not os.path.exists(filename):\n",
        "            continue  # Skip if the file doesn't exist\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "\n",
        "print(\"Video saved as 'pose_video_with_prediction.mp4'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlCDNnUiciCa"
      },
      "outputs": [],
      "source": [
        "# Create a video from the saved images\n",
        "with imageio.get_writer('pose_video_3.mp4', fps=10) as writer:\n",
        "    for frame_number in range(df_trail_run['frame'].max() + 1):\n",
        "        filename = f'frames/frame_{frame_number:03d}.png'\n",
        "        if not os.path.exists(filename):\n",
        "            continue  # Skip if the file doesn't exist\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "\n",
        "print(\"Video saved as 'pose_video_3.mp4'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}